{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N559bBQunTEn"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awnfHB6IDKvX"
   },
   "outputs": [],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPlQLXARmV5B"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import math \n",
    "import re\n",
    "import gensim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "from wordcloud import WordCloud\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvC1OkLFnZJ_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ph3yDMamV5O"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "df = pd.read_csv('/content/gdrive/My Drive/yelp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuR-YDtys-sy"
   },
   "outputs": [],
   "source": [
    "print(\"Count according to the cool level\")\n",
    "Cool_count = df['cool'].value_counts()\n",
    "print(Cool_count)\n",
    "\n",
    "print(\"Count according to the useful level\")\n",
    "Useful_count = df['useful'].value_counts()\n",
    "print(Useful_count)\n",
    "\n",
    "print(\"Count according to the funny level\")\n",
    "Funny_count = df['funny'].value_counts()\n",
    "print(Funny_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZ2jLZb0u4dY"
   },
   "outputs": [],
   "source": [
    "#remove newlines in text\n",
    "def preprocess(text):\n",
    "    return text.replace('\\n\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKnVEJzowXKN"
   },
   "outputs": [],
   "source": [
    "#create list of all reviews with the new line symbols removed\n",
    "all_reviews = []\n",
    "for i in df.index:\n",
    "    all_reviews.append(preprocess(df.text[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTD87spuwbtG"
   },
   "outputs": [],
   "source": [
    "#calculate tf-idf\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_table = tfidf.fit_transform(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvGjsH79weC9"
   },
   "outputs": [],
   "source": [
    "n_features = len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgqiTao4HCi2"
   },
   "outputs": [],
   "source": [
    "#save average tf-idf for each review\n",
    "avg_non_zero_tf_idf =[]\n",
    "avg_tf_idf =[]\n",
    "for i in range(len(all_reviews)):\n",
    "    \n",
    "    non_zero_doc_tf_idf = tfidf_table[i].tocoo().data.tolist()\n",
    "    \n",
    "    if len(non_zero_doc_tf_idf) ==0:\n",
    "        avg_non_zero_tf_idf.append(0)\n",
    "        \n",
    "    else: avg_non_zero_tf_idf.append(sum(non_zero_doc_tf_idf)/len(non_zero_doc_tf_idf))\n",
    "    \n",
    "    avg_tf_idf.append(10000*tfidf_table[i].tocoo().data.sum()/n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aof2dgpVHEAf"
   },
   "outputs": [],
   "source": [
    "#calculate other features for the model\n",
    "\n",
    "stop_words=stopwords.words(\"english\")\n",
    "\n",
    "def is_not_only_punctuation(word):\n",
    "    return not all([x  in string.punctuation for x in word  ]) \n",
    "\n",
    "n_words =[] #number of words\n",
    "n_sent =[] #number of sentences\n",
    "for review in all_reviews:\n",
    "    word_list = nltk.word_tokenize(review)\n",
    "    #word_list_no_puncuation = [word for word in word_list if is_not_only_punctuation(word)]\n",
    "    n_words.append(len(n_words))\n",
    "    n_sent.append( len(nltk.sent_tokenize(review)))\n",
    "    \n",
    "n_paras = []  #number of paragraphs\n",
    "for i in df.index:\n",
    "     n_paras.append(df.text[i].count(\"\\n\\n\")+1)\n",
    "    \n",
    "\n",
    "print(\"Total number of words are:\", sum(n_words))\n",
    "print(\"Total number of sentences are:\", sum(n_sent))\n",
    "print(\"Total number of paragraphs are:\", sum(n_paras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvY6RLrFJjs5"
   },
   "outputs": [],
   "source": [
    "#create binary variables for cool, funny, and useful\n",
    "df['is_cool']= df.cool>1\n",
    "df['is_funny']= df.funny>1\n",
    "df['is_useful']= df.useful>1\n",
    "\n",
    "#create binary variables for stars\n",
    "df['star_1']= df.stars == 1\n",
    "df['star_2']= df.stars == 2\n",
    "df['star_3']= df.stars == 3\n",
    "df['star_4']= df.stars == 4\n",
    "df['star_5']= df.stars == 5\n",
    "\n",
    "#save other features\n",
    "df['avg_non_zero_tf_idf'] = avg_non_zero_tf_idf \n",
    "df['avg_tf_idf'] = avg_tf_idf\n",
    "df['n_words']= n_words\n",
    "df['n_sent']= n_sent\n",
    "df['n_paras']= n_paras\n",
    "\n",
    "df['exclaim'] = df.text.str.contains('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5HQO1cePBZo"
   },
   "outputs": [],
   "source": [
    "lexical_diversity =[]\n",
    "\n",
    "for review in all_reviews:\n",
    "    word_list = nltk.word_tokenize(review.lower())\n",
    "    unique_word_list = set(word_list)\n",
    "\n",
    "    lexical_diversity.append(len(unique_word_list)/len(word_list))    \n",
    "df['LD']= lexical_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOWn-nzWPEGP"
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "## to account for sentiment, we can include the results from sentinment analysis \n",
    "#into the model as features\n",
    "\n",
    "## try both numerical (positive, negative, neutral scores) or binary\n",
    "# a review can have a high amount of both positive and negative sentiment,\n",
    "# so keep both positive and negative aspects seperate instead of using compound score\n",
    "\n",
    "\n",
    "neg = []\n",
    "pos =[]\n",
    "neu = []\n",
    "for review in all_reviews:\n",
    "    sent=analyzer.polarity_scores(review)\n",
    "\n",
    "    neg.append(sent['neg'])\n",
    "    pos.append(sent['pos'])\n",
    "    neu.append(sent['neu'])\n",
    "    \n",
    "df['neg']= neg\n",
    "df['pos']= pos\n",
    "df['neu']= neu\n",
    "\n",
    "df['is_neg']= df['neg']>.5\n",
    "df['is_pos']= df['pos']>.5\n",
    "df['is_neu']= df['neu']>.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qc0RM84GQJFB"
   },
   "source": [
    "# Average TF IDF over non zero values (i.e, only over words in the doc)\n",
    "through trail and error this is the best model I found, based of R2 of test set\n",
    "\n",
    "coefs for cool and useful are (-) and funny is (+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "xd9T8FqtPVKj",
    "outputId": "728fbf00-afac-4c56-bc18-15132a0ae505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for is_pos is 0.10993827359513889\n",
      "The coefficient for is_neg is 0.19990059373579422\n",
      "The coefficient for is_cool is -0.00963089254682753\n",
      "The coefficient for is_funny is 0.007797862753552836\n",
      "The coefficient for is_useful is -0.012095779065884747\n",
      "The coefficient for star_1 is 0.003408518468594225\n",
      "The coefficient for star_2 is -0.0038517214683838714\n",
      "The coefficient for star_3 is -0.008031035867474617\n",
      "The coefficient for star_4 is 0.0012319870904246993\n",
      "The coefficient for star_5 is 0.007242251776838842\n",
      "The coefficient for n_sent is -0.01168984898140521\n",
      "The coefficient for n_paras is -0.0032775392523697947\n",
      "Test RMSE::  0.07880016174460247\n",
      "Test score:: 0.5940129842958047\n"
     ]
    }
   ],
   "source": [
    "#split into train and test set \n",
    "\n",
    "X = df[['is_pos','is_neg','is_cool','is_funny','is_useful','star_1','star_2','star_3','star_4','star_5','n_sent','n_paras']]\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#fit model\n",
    "regression_model = LinearRegression(fit_intercept=True)\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))\n",
    "\n",
    "pred=regression_model.predict(X_test) #make prediction on test set\n",
    "error = math.sqrt(metrics.mean_squared_error(y_test,pred)) #calculate rmse\n",
    "\n",
    "print('Test RMSE:: ',error)\n",
    "print('Test score::',regression_model.score(X_test,y_test)) #R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmFFikNbTrJc"
   },
   "source": [
    "# Average tf-idf over all values (all words)\n",
    "Cool and useful (+) and funny is (-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "sA5mmKmbSm3w",
    "outputId": "d6c092fd-476a-48e4-9399-501766b28cb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for pos is 0.2779607247212962\n",
      "The coefficient for neg is 0.2047841913198902\n",
      "The coefficient for is_cool is -0.00478267725038981\n",
      "The coefficient for is_funny is 0.002917193024210482\n",
      "The coefficient for is_useful is -0.006722879637917491\n",
      "The coefficient for star_1 is 0.014561080832083864\n",
      "The coefficient for star_2 is 0.005010500996677312\n",
      "The coefficient for star_3 is -0.004204690558490066\n",
      "The coefficient for star_4 is -0.008615791124996032\n",
      "The coefficient for star_5 is -0.006751100145273945\n",
      "The coefficient for n_sent is -0.003843231827473398\n",
      "The coefficient for n_paras is -0.0006349143239790661\n",
      "The coefficient for exclaim is -0.00891881551923842\n",
      "Test RMSE::  0.04901618012917836\n",
      "Test score:: 0.5001241830050258\n"
     ]
    }
   ],
   "source": [
    "#split into train and test set \n",
    "\n",
    "X = df[['pos','neg','is_cool','is_funny','is_useful','star_1','star_2','star_3','star_4','star_5','n_sent','n_paras','exclaim']]\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#fit model\n",
    "regression_model = LinearRegression(fit_intercept=True)\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))\n",
    "\n",
    "pred=regression_model.predict(X_test) #make prediction on test set\n",
    "error = math.sqrt(metrics.mean_squared_error(y_test,pred)) #calculate rmse\n",
    "\n",
    "print('Test RMSE:: ',error)\n",
    "print('Test score::',regression_model.score(X_test,y_test)) #R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoKcQvcuTlJ3"
   },
   "source": [
    "# Lexical diversity\n",
    "Cool and useful (-) and funny is (+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "lvHUolaaStEI",
    "outputId": "698a0cf1-84fc-4448-efc7-fdcfcc079f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for pos is 0.23369753575272212\n",
      "The coefficient for neg is 0.17962682803630117\n",
      "The coefficient for is_cool is -0.007988674394703932\n",
      "The coefficient for is_funny is 0.006936270814023489\n",
      "The coefficient for is_useful is -0.010729049113249272\n",
      "The coefficient for star_1 is 0.012491592738215372\n",
      "The coefficient for star_2 is 0.0015502839771365734\n",
      "The coefficient for star_3 is -0.007128739912120648\n",
      "The coefficient for star_4 is -0.005138536324285967\n",
      "The coefficient for star_5 is -0.0017746004789447236\n",
      "The coefficient for n_sent is -0.011477299480761649\n",
      "The coefficient for n_paras is -0.00265164041493271\n",
      "Test RMSE::  0.07729747946928243\n",
      "Test score:: 0.6093493137907626\n"
     ]
    }
   ],
   "source": [
    "#split into train and test set \n",
    "\n",
    "X = df[['pos','neg','is_cool','is_funny','is_useful','star_1','star_2','star_3','star_4','star_5','n_sent','n_paras']]\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "#fit model\n",
    "regression_model = LinearRegression(fit_intercept=True)\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))\n",
    "\n",
    "pred=regression_model.predict(X_test) #make prediction on test set\n",
    "error = math.sqrt(metrics.mean_squared_error(y_test,pred)) #calculate rmse\n",
    "\n",
    "print('Test RMSE:: ',error)\n",
    "print('Test score::',regression_model.score(X_test,y_test)) #R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9oZK_OeTjr2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final Kishore TM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
